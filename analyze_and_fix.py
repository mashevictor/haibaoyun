#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†ææµ‹è¯•ç»“æœå¹¶ç”Ÿæˆä¿®å¤æŠ¥å‘Š
"""
import os
import re
from pathlib import Path
import json

def find_chinese_in_html(file_path):
    """åœ¨HTMLæ–‡ä»¶ä¸­æŸ¥æ‰¾ä¸­æ–‡å­—ç¬¦"""
    chinese_regex = re.compile(r'[\u4e00-\u9fa5]+')
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
            
            for line_num, line in enumerate(lines, 1):
                # è·³è¿‡scriptå’Œstyleæ ‡ç­¾å†…çš„å†…å®¹
                if '<script' in line.lower() or '<style' in line.lower():
                    continue
                
                # æŸ¥æ‰¾ä¸­æ–‡
                matches = chinese_regex.findall(line)
                if matches:
                    # æ£€æŸ¥æ˜¯å¦æœ‰data-i18nå±æ€§
                    has_data_i18n = 'data-i18n' in line
                    
                    # æå–æ ‡ç­¾å
                    tag_match = re.search(r'<(\w+)', line)
                    tag_name = tag_match.group(1) if tag_match else 'unknown'
                    
                    # æå–æ–‡æœ¬å†…å®¹ï¼ˆå»é™¤HTMLæ ‡ç­¾ï¼‰
                    text_match = re.search(r'>([^<]+)<', line)
                    text_content = text_match.group(1).strip() if text_match else line.strip()[:50]
                    
                    issues.append({
                        'line': line_num,
                        'text': text_content,
                        'tag': tag_name,
                        'has_data_i18n': has_data_i18n,
                        'chinese': ' '.join(matches[:3])  # åªæ˜¾ç¤ºå‰3ä¸ªåŒ¹é…
                    })
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    return issues

def analyze_pages():
    """åˆ†ææ‰€æœ‰é¡µé¢"""
    pages = [
        'index.html',
        'pages/scenarios.html',
        'pages/token.html',
        'pages/hardware-factory.html',
        'pages/research-strength.html',
        'pages/developer.html',
        'pages/about.html',
        'pages/chain.html',
        'pages/infra.html',
        'pages/market.html',
        'pages/dao.html',
        'pages/decloud.html',
    ]
    
    results = {}
    
    print("=" * 70)
    print("åˆ†æé¡µé¢ä¸­çš„ä¸­æ–‡å†…å®¹...")
    print("=" * 70)
    print()
    
    for page_path in pages:
        if os.path.exists(page_path):
            issues = find_chinese_in_html(page_path)
            if issues:
                results[page_path] = issues
                print(f"âŒ {page_path}: å‘ç° {len(issues)} å¤„ä¸­æ–‡")
            else:
                print(f"âœ… {page_path}: æ— ä¸­æ–‡")
    
    return results

def generate_fix_report(results):
    """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
    print()
    print("=" * 70)
    print("ä¿®å¤æŠ¥å‘Š")
    print("=" * 70)
    print()
    
    total_issues = sum(len(issues) for issues in results.values())
    missing_i18n = sum(
        sum(1 for issue in issues if not issue['has_data_i18n'])
        for issues in results.values()
    )
    
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   - æœ‰é—®é¢˜çš„é¡µé¢æ•°: {len(results)}")
    print(f"   - æ€»é—®é¢˜æ•°: {total_issues}")
    print(f"   - ç¼ºå°‘data-i18nçš„é—®é¢˜: {missing_i18n}")
    print()
    
    if results:
        print("ğŸ”§ éœ€è¦ä¿®å¤çš„é¡µé¢:")
        print()
        
        for page_path, issues in results.items():
            print(f"ğŸ“„ {page_path}")
            print(f"   é—®é¢˜æ•°: {len(issues)}")
            
            # æŒ‰æ˜¯å¦æœ‰data-i18nåˆ†ç»„
            with_i18n = [i for i in issues if i['has_data_i18n']]
            without_i18n = [i for i in issues if not i['has_data_i18n']]
            
            if without_i18n:
                print(f"   âš ï¸  ç¼ºå°‘data-i18n: {len(without_i18n)} å¤„")
                print(f"   å‰3ä¸ªé—®é¢˜:")
                for idx, issue in enumerate(without_i18n[:3], 1):
                    print(f"      {idx}. ç¬¬{issue['line']}è¡Œ: {issue['text'][:50]}...")
                    print(f"         ä¸­æ–‡: {issue['chinese']}")
            
            if with_i18n:
                print(f"   â„¹ï¸  æœ‰data-i18nä½†ä»æœ‰ä¸­æ–‡: {len(with_i18n)} å¤„")
                print(f"   (å¯èƒ½æ˜¯ç¿»è¯‘é”®ç¼ºå¤±æˆ–ç¿»è¯‘æœªç”Ÿæ•ˆ)")
            
            print()
    
    # ä¿å­˜JSONæŠ¥å‘Š
    report = {
        'summary': {
            'total_pages_with_issues': len(results),
            'total_issues': total_issues,
            'missing_i18n_count': missing_i18n
        },
        'details': results
    }
    
    with open('fix_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("ğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: fix_report.json")
    print()

def main():
    results = analyze_pages()
    generate_fix_report(results)
    
    if results:
        print("=" * 70)
        print("ğŸ’¡ ä¿®å¤å»ºè®®:")
        print("=" * 70)
        print()
        print("1. å¯¹äºç¼ºå°‘data-i18nçš„å…ƒç´ :")
        print("   - æ·»åŠ data-i18nå±æ€§")
        print("   - åœ¨js/languages.jsä¸­æ·»åŠ å¯¹åº”çš„ç¿»è¯‘é”®")
        print()
        print("2. å¯¹äºæœ‰data-i18nä½†ä»æœ‰ä¸­æ–‡çš„å…ƒç´ :")
        print("   - æ£€æŸ¥js/languages.jsä¸­å¯¹åº”çš„ç¿»è¯‘é”®æ˜¯å¦å­˜åœ¨")
        print("   - æ£€æŸ¥ç¿»è¯‘é”®çš„è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆåµŒå¥—é”®ï¼‰")
        print("   - æ£€æŸ¥LanguageManageræ˜¯å¦æ­£ç¡®å¤„ç†ç¿»è¯‘")
        print()
        print("3. è¿è¡Œæµ‹è¯•éªŒè¯ä¿®å¤:")
        print("   - npm test")
        print()

if __name__ == '__main__':
    main()
