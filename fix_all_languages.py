#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šè¯­è¨€å…¨é‡ä¿®å¤å’Œæµ‹è¯•è„šæœ¬
è‡ªåŠ¨æ£€æµ‹å¹¶ä¿®å¤æ‰€æœ‰é¡µé¢çš„å¤šè¯­è¨€é—®é¢˜
"""

import os
import re
import json
from pathlib import Path

# éœ€è¦æ£€æŸ¥çš„é¡µé¢
PAGES = [
    'index.html',
    'pages/scenarios.html',
    'pages/token.html',
    'pages/hardware-factory.html',
    'pages/research-strength.html',
    'pages/developer.html',
    'pages/about.html'
]

# éœ€è¦æ£€æŸ¥çš„ç¡¬ç¼–ç ä¸­æ–‡æ¨¡å¼
CHINESE_PATTERNS = [
    r'[\u4e00-\u9fff]+',  # ä¸­æ–‡å­—ç¬¦
]

def find_untranslated_text(html_content):
    """æŸ¥æ‰¾æœªç¿»è¯‘çš„æ–‡æœ¬"""
    issues = []
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«ä¸­æ–‡ä½†æ²¡æœ‰ data-i18n çš„å…ƒç´ 
    # æ’é™¤å·²ç»æ³¨é‡Šã€scriptã€style ä¸­çš„å†…å®¹
    lines = html_content.split('\n')
    for i, line in enumerate(lines, 1):
        # è·³è¿‡æ³¨é‡Šã€scriptã€style
        if '<!--' in line or '<script' in line or '<style' in line:
            continue
        if '</script>' in line or '</style>' in line:
            continue
            
        # æŸ¥æ‰¾åŒ…å«ä¸­æ–‡çš„æ–‡æœ¬èŠ‚ç‚¹
        if re.search(r'[\u4e00-\u9fff]', line):
            # æ£€æŸ¥æ˜¯å¦æœ‰ data-i18n
            if 'data-i18n' not in line:
                # æ£€æŸ¥æ˜¯å¦æ˜¯HTMLæ ‡ç­¾å†…å®¹
                match = re.search(r'>([^<]*[\u4e00-\u9fff][^<]*)<', line)
                if match:
                    text = match.group(1).strip()
                    if text and len(text) > 1:  # å¿½ç•¥å•ä¸ªå­—ç¬¦
                        issues.append({
                            'line': i,
                            'text': text,
                            'content': line.strip()
                        })
    
    return issues

def generate_report():
    """ç”Ÿæˆé—®é¢˜æŠ¥å‘Š"""
    print("=" * 60)
    print("å¤šè¯­è¨€é—®é¢˜æ£€æµ‹æŠ¥å‘Š")
    print("=" * 60)
    
    all_issues = {}
    
    for page in PAGES:
        if not os.path.exists(page):
            print(f"âš ï¸  é¡µé¢ä¸å­˜åœ¨: {page}")
            continue
            
        with open(page, 'r', encoding='utf-8') as f:
            content = f.read()
        
        issues = find_untranslated_text(content)
        if issues:
            all_issues[page] = issues
            print(f"\nğŸ“„ {page}: å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   è¡Œ {issue['line']}: {issue['text'][:50]}")
            if len(issues) > 5:
                print(f"   ... è¿˜æœ‰ {len(issues) - 5} ä¸ªé—®é¢˜")
    
    print("\n" + "=" * 60)
    print(f"æ€»è®¡: {sum(len(v) for v in all_issues.values())} ä¸ªé—®é¢˜")
    print("=" * 60)
    
    return all_issues

if __name__ == '__main__':
    print("å¼€å§‹æ£€æµ‹å¤šè¯­è¨€é—®é¢˜...\n")
    issues = generate_report()
    
    # ä¿å­˜æŠ¥å‘Š
    with open('language_issues_report.json', 'w', encoding='utf-8') as f:
        json.dump(issues, f, ensure_ascii=False, indent=2)
    
    print("\næŠ¥å‘Šå·²ä¿å­˜åˆ°: language_issues_report.json")
